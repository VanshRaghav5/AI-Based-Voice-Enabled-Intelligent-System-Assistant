# OmniAssist AI -- Voice-Enabled Intelligent System Assistant

OmniAssist AI is a hybrid (offline-first) voice-enabled intelligent
assistant designed to enhance human--computer interaction. It listens to
user speech, understands it using AI models, and responds naturally
using high-quality text-to-speech, with controlled system access.

This project is developed as an academic mini-project with a focus on
offline capability, modular architecture, and production-ready design.

------------------------------------------------------------------------

## ğŸš€ Key Features

-   ğŸ™ï¸ Real-time voice input through microphone
-   ğŸ§  Offline speech-to-text using Whisper
-   ğŸ”Š Offline neural text-to-speech using Piper
-   ğŸŒ FastAPI backend for modular API-based control
-   ğŸ§© Clean separation of voice, API, and logic layers
-   ğŸ” Privacy-friendly (offline by default)

------------------------------------------------------------------------

## ğŸ§  Current System Architecture

User Speech\
â†“\
Microphone Input\
â†“\
Whisper (Speech-to-Text -- Offline)\
â†“\
Intent / Logic Layer (Upcoming)\
â†“\
Piper (Text-to-Speech -- Offline)\
â†“\
Audio Response

------------------------------------------------------------------------

## ğŸ“ Project Structure

OmniAssist-AI/

backend/\
Â Â Â Â app.py\
Â Â Â Â requirements.txt

Â Â Â Â api/\
Â Â Â Â Â Â Â Â voice.py

Â Â Â Â voice/\
Â Â Â Â Â Â Â Â recorder.py\
Â Â Â Â Â Â Â Â stt.py\
Â Â Â Â Â Â Â Â tts.py\
Â Â Â Â Â Â Â Â piper/ (local runtime -- ignored in Git)

desktop-app/ (Future UI)\
docs/\
README.md

------------------------------------------------------------------------

## ğŸ› ï¸ Technologies Used

-   Python 3.10+
-   FastAPI
-   Whisper (Offline STT)
-   Piper TTS (Offline TTS)
-   SoundDevice & SciPy
-   Uvicorn

------------------------------------------------------------------------

## âš™ï¸ Setup Instructions

1.  Clone the repository\
    git clone `<repository-url>`{=html}\
    cd OmniAssist-AI

2.  Create virtual environment\
    python -m venv venv

3.  Activate environment\
    Windows: venv`\Scripts`{=tex}`\activate  `{=tex} macOS/Linux: source
    venv/bin/activate

4.  Install dependencies\
    pip install -r backend/requirements.txt

5.  Setup Piper manually inside backend/voice/piper/\
    Required files:

    -   piper.exe
    -   espeak-ng-data/
    -   en_US-danny-low.onnx
    -   en_US-danny-low.onnx.json

------------------------------------------------------------------------

## â–¶ï¸ Running the Backend

uvicorn backend.app:app --reload

Open: http://127.0.0.1:8000/ http://127.0.0.1:8000/docs

------------------------------------------------------------------------

## ğŸ¤ Voice Test

Use: POST /api/voice/test

Flow: Microphone â†’ Whisper â†’ Text â†’ Piper â†’ Spoken Response

------------------------------------------------------------------------

## ğŸ“Œ Project Status

âœ” Voice Input Module -- Completed\
âœ” Offline STT & TTS -- Completed\
ğŸŸ¡ Intent Detection -- In Progress\
ğŸŸ¡ Desktop App -- Planned

------------------------------------------------------------------------

## ğŸ“œ License

Academic and educational use only.
